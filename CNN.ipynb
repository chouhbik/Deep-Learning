{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "39KpvOvDY976"
   },
   "source": [
    "## Simple Convolutional Neural Network\n",
    "In this part, we learn to:\n",
    "- train a simple CNN on MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HR8ar9ITY977"
   },
   "source": [
    "### 1. Loading Essential Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15427,
     "status": "ok",
     "timestamp": 1533209292899,
     "user": {
      "displayName": "Mohammad Doosti Lakhani",
      "photoUrl": "//lh5.googleusercontent.com/-UVQKn-_bjas/AAAAAAAAAAI/AAAAAAAAACc/Nr22-zVsFzc/s50-c-k-no/photo.jpg",
      "userId": "112537701770884493684"
     },
     "user_tz": -270
    },
    "id": "C34tpVnLY978",
    "outputId": "fcd23a5f-7b54-4a8d-882f-7f8ede9b6420"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FqnGRTbqY98C"
   },
   "source": [
    "### 2. Seting the hyper-parameters Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0HArRH9qY98E"
   },
   "outputs": [],
   "source": [
    "batch_size = 128    # Here we define the batch size value\n",
    "num_classes = 10    # Assign the number of class exists in MNIST dataset\n",
    "epochs = 12       # Total Number of iteratin on mnist dataset \n",
    "img_rows, img_cols = 28, 28        # input image dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J5wf7cvtY98H"
   },
   "source": [
    "### 3. Loading MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2892,
     "status": "ok",
     "timestamp": 1533209339994,
     "user": {
      "displayName": "Mohammad Doosti Lakhani",
      "photoUrl": "//lh5.googleusercontent.com/-UVQKn-_bjas/AAAAAAAAAAI/AAAAAAAAACc/Nr22-zVsFzc/s50-c-k-no/photo.jpg",
      "userId": "112537701770884493684"
     },
     "user_tz": -270
    },
    "id": "u5UUTTfBY98I",
    "outputId": "207f00c7-be9b-4382-ab05-61648dfcf2ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0ivj-IZ1Y98N"
   },
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NcbM7HpGY98R"
   },
   "source": [
    "### 5. Here we are going to understand:\n",
    "1. How can we change variables type?\n",
    "2. How can we normalized the numbers in a range between 0 and 1? This is a simple solution, But there are other ways. google it:)\n",
    "3. How can we get the exact dimension of each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2488,
     "status": "ok",
     "timestamp": 1533209391595,
     "user": {
      "displayName": "Mohammad Doosti Lakhani",
      "photoUrl": "//lh5.googleusercontent.com/-UVQKn-_bjas/AAAAAAAAAAI/AAAAAAAAACc/Nr22-zVsFzc/s50-c-k-no/photo.jpg",
      "userId": "112537701770884493684"
     },
     "user_tz": -270
    },
    "id": "fYJKdTAMY98R",
    "outputId": "5f43f8e9-694e-4275-ce99-37d31aa180b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')      # This is the way we change the variable type\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255                           # Here we normalize the data between 0 and 1\n",
    "x_test /= 255                            # Here we normalize the data between 0 and 1\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tF-4i672Y98V"
   },
   "source": [
    "### 6. Using this way, you can find which classes each data point belongs to!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6855,
     "status": "ok",
     "timestamp": 1533209402111,
     "user": {
      "displayName": "Mohammad Doosti Lakhani",
      "photoUrl": "//lh5.googleusercontent.com/-UVQKn-_bjas/AAAAAAAAAAI/AAAAAAAAACc/Nr22-zVsFzc/s50-c-k-no/photo.jpg",
      "userId": "112537701770884493684"
     },
     "user_tz": -270
    },
    "id": "EFEZgUHfY98W",
    "outputId": "28cf58a8-9929-4d6d-d42e-60143863e9fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])    # This refers to that the sample #1 is related to Class 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pNe30LlDY98Z"
   },
   "source": [
    "### 7.Convert target representation from a simple scalar to one-hot representation:\n",
    "One-Hot encoding. A one hot encoding is a representation of categorical variables as binary vectors. Each integer value is represented as a binary vector that is all zero values except the index of the integer, which is marked with a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7DcEQb7WY98a"
   },
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1317,
     "status": "ok",
     "timestamp": 1533209431172,
     "user": {
      "displayName": "Mohammad Doosti Lakhani",
      "photoUrl": "//lh5.googleusercontent.com/-UVQKn-_bjas/AAAAAAAAAAI/AAAAAAAAACc/Nr22-zVsFzc/s50-c-k-no/photo.jpg",
      "userId": "112537701770884493684"
     },
     "user_tz": -270
    },
    "id": "gSy5p80YY98c",
    "outputId": "d59a2993-d995-463d-a6ee-110cb6f40a7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])    # above command assign 1 to 5th element of a vector and others have value 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cCthtyRXY98g"
   },
   "source": [
    "### So far, all above operations are easy to understand. If you want to know more on each function operation, just use \"shift + tab\" on each function name. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gNeAgxCIY98g"
   },
   "source": [
    "### 8. Now, this is your turn. we are going to define a sequential model describer in following:\n",
    "- Conv2D: filters = 32, kernel_size = (3,3), activation = 'relu', input_shape = (1, 28, 28)\n",
    "- Conv2D: filters = 64, kernel_size = (3,3), activation = 'relu'\n",
    "- MaxPooling2D: pool_size=(2, 2)\n",
    "- Dropout: rate = 0.25\n",
    "- Flatten\n",
    "- Dense: units = 128, activation='relu'\n",
    "- Dropout: rate = 0.5\n",
    "- Dense: units = 10, activation='softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sVpMqhy3Y98h"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3,3),input_shape = (28,28,1), strides=(1, 1), padding='valid', data_format=None, activation='relu', use_bias=True))\n",
    "model.add(Conv2D(64, kernel_size = (3,3), strides=(1, 1), padding='valid', data_format=None, activation='relu', use_bias=True))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', use_bias=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax', use_bias=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Do8VdKYgY98j"
   },
   "source": [
    "### 9. Same as before, we need to compile our above model with an optimizer and a caregorical loss function. You already know it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "kPECuTWkY98k"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KOv8Wkr6Y98n"
   },
   "source": [
    "### 10. Here, we try to fit our model on MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 122151,
     "status": "ok",
     "timestamp": 1533210653734,
     "user": {
      "displayName": "Mohammad Doosti Lakhani",
      "photoUrl": "//lh5.googleusercontent.com/-UVQKn-_bjas/AAAAAAAAAAI/AAAAAAAAACc/Nr22-zVsFzc/s50-c-k-no/photo.jpg",
      "userId": "112537701770884493684"
     },
     "user_tz": -270
    },
    "id": "eqOyCU7WY98p",
    "outputId": "af6afb2f-c8b0-4a2a-8b44-a71207f55838"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.2676 - acc: 0.9172 - val_loss: 0.0596 - val_acc: 0.9813\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0889 - acc: 0.9736 - val_loss: 0.0450 - val_acc: 0.9850\n",
      "Epoch 3/12\n",
      "28416/60000 [=============>................] - ETA: 4s - loss: 0.0701 - acc: 0.979560000/60000 [==============================] - 10s 165us/step - loss: 0.0677 - acc: 0.9802 - val_loss: 0.0355 - val_acc: 0.9872\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0549 - acc: 0.9841 - val_loss: 0.0326 - val_acc: 0.9883\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0473 - acc: 0.9854 - val_loss: 0.0318 - val_acc: 0.9890\n",
      "Epoch 6/12\n",
      "  512/60000 [..............................] - ETA: 9s - loss: 0.0493 - acc: 0.9863 60000/60000 [==============================] - 10s 165us/step - loss: 0.0406 - acc: 0.9878 - val_loss: 0.0293 - val_acc: 0.9893\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0386 - acc: 0.9883 - val_loss: 0.0284 - val_acc: 0.9903\n",
      "Epoch 8/12\n",
      "55040/60000 [==========================>...] - ETA: 0s - loss: 0.0334 - acc: 0.989760000/60000 [==============================] - 10s 165us/step - loss: 0.0336 - acc: 0.9896 - val_loss: 0.0285 - val_acc: 0.9904\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0322 - acc: 0.9899 - val_loss: 0.0302 - val_acc: 0.9900\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0298 - acc: 0.9912 - val_loss: 0.0282 - val_acc: 0.9909\n",
      "Epoch 11/12\n",
      " 4736/60000 [=>............................] - ETA: 8s - loss: 0.0295 - acc: 0.990160000/60000 [==============================] - 10s 164us/step - loss: 0.0300 - acc: 0.9907 - val_loss: 0.0325 - val_acc: 0.9912\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0264 - acc: 0.9920 - val_loss: 0.0248 - val_acc: 0.9919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd9e00729b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2675,
     "status": "ok",
     "timestamp": 1533210672730,
     "user": {
      "displayName": "Mohammad Doosti Lakhani",
      "photoUrl": "//lh5.googleusercontent.com/-UVQKn-_bjas/AAAAAAAAAAI/AAAAAAAAACc/Nr22-zVsFzc/s50-c-k-no/photo.jpg",
      "userId": "112537701770884493684"
     },
     "user_tz": -270
    },
    "id": "YczU4v9RY98r",
    "outputId": "90386af9-d5d9-4a83-a537-371fffecfe5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.02479468177455092\n",
      "Test accuracy: 0.9919\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0lGeZAuSY98u"
   },
   "source": [
    "## Pre-trained models and Data Augmentation:\n",
    "In this section, we are going to use a pre-trained model called MobileNet. Using this network and a new dataset, we train a newly defined Convolutinal Neural Network. A comprehensive list of goals are presented bellow (Be cautious of What I list. Think about them)\n",
    "\n",
    "1. Finetuning A pre-trained deep neural network\n",
    "2. Training on a new dataset gave you before handson.\n",
    "3. Data Augmenting using KERAS Utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8zRutFLDY98v"
   },
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xLUUbdHPY98y"
   },
   "source": [
    "### 0. Hyper-parameters definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vrM05ZbmY98y"
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 128, 128    # input image has size (3, 128, 128)\n",
    "train_data_dir = \"data/train\"    # Location of training data\n",
    "validation_data_dir = \"data/val\"    # Location of validation data\n",
    "nb_train_samples = 244       # Total Number of Training samples\n",
    "nb_validation_samples = 153       # Total Number of Validations samples\n",
    "batch_size = 16\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PkUaTQvtY982"
   },
   "source": [
    "### 1.Using commands introduced in hands on CNN, try to load MobileNet instead of VGG19. Just change the name ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10311,
     "status": "ok",
     "timestamp": 1533212247905,
     "user": {
      "displayName": "Mohammad Doosti Lakhani",
      "photoUrl": "//lh5.googleusercontent.com/-UVQKn-_bjas/AAAAAAAAAAI/AAAAAAAAACc/Nr22-zVsFzc/s50-c-k-no/photo.jpg",
      "userId": "112537701770884493684"
     },
     "user_tz": -270
    },
    "id": "MaHOMhsAY983",
    "outputId": "2b0b3c6c-c4bd-49f5-9f87-940ed21e2f9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_128_tf_no_top.h5\n",
      "17227776/17225924 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.mobilenet import MobileNet\n",
    "model = MobileNet(weights='imagenet',include_top= False,input_shape = (128,128,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hCOF5dHRY989"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s6US1MdXY99A"
   },
   "source": [
    "### 2. try to freeze just all of the layers in model included above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 867,
     "status": "ok",
     "timestamp": 1533211149893,
     "user": {
      "displayName": "Mohammad Doosti Lakhani",
      "photoUrl": "//lh5.googleusercontent.com/-UVQKn-_bjas/AAAAAAAAAAI/AAAAAAAAACc/Nr22-zVsFzc/s50-c-k-no/photo.jpg",
      "userId": "112537701770884493684"
     },
     "user_tz": -270
    },
    "id": "-5D8Fs6rgV4V",
    "outputId": "f39a1dd1-8507-4810-aa5f-a00d8f8ccf26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7_mF-CPtY99A"
   },
   "outputs": [],
   "source": [
    "# Freeze the first five layers which you don't want to train. \n",
    "for i in range(0,len(model.layers)):   ######## You shold change this line ########\n",
    "    model.layers[i] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PogU50dJY99C"
   },
   "source": [
    "### 3. Here we are going to attach the new classifier at the end of pretrained model. This is a new technique whcih we are going to explore more.\n",
    "- Flatten Layer\n",
    "- Desne Layer: units: 1024, activation = \"relu\"\n",
    "- Dropout: rate = 0.5\n",
    "- Desne Layer: units: 512, activation = \"relu\"\n",
    "- Desne Layer: units: 2, activation = \"softamax\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "L2wyWbImY99D"
   },
   "outputs": [],
   "source": [
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu', use_bias=True)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu', use_bias=True)(x)\n",
    "x = Dense(2, activation='softmax', use_bias=True)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "v-3oJxeEY99F"
   },
   "outputs": [],
   "source": [
    "# creating the final model \n",
    "model_final = Model(inputs = model.input, outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2fgBJEC4Y99H"
   },
   "outputs": [],
   "source": [
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "egSEup5ZY99K"
   },
   "outputs": [],
   "source": [
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bFsSOXwCY99M"
   },
   "source": [
    "### 4. Define a data augmentator as presented in CNN hands-on slides according to the following parameters:\n",
    "- rescale = 1./255\n",
    "- horizontal_flip = True\n",
    "- fill_mode = \"nearest\"\n",
    "- zoom_range = 0.6\n",
    "- width_shift_range = 0.2\n",
    "- height_shift_range=0.4\n",
    "- rotation_range=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "eLYq9uO8Y99N"
   },
   "outputs": [],
   "source": [
    "# This an augmentator for test dataset\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                    horizontal_flip = True,\n",
    "                    fill_mode = \"nearest\",\n",
    "                    zoom_range = 0.6,\n",
    "                    width_shift_range = 0.2,\n",
    "                    height_shift_range=0.4,\n",
    "                    rotation_range=25)\n",
    "\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                    horizontal_flip = True,\n",
    "                    fill_mode = \"nearest\",\n",
    "                    zoom_range = 0.6,\n",
    "                    width_shift_range = 0.2,\n",
    "                    height_shift_range=0.4,\n",
    "                    rotation_range=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XvwTkUwgY99Q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3APePLnfY99S"
   },
   "source": [
    "### 5. in This section, What we are going to do is to create a dataloader for loading data along with augmentator.\n",
    "1. Train Loader Setting\n",
    "\n",
    "    - directory = train_data_dir\n",
    "    - target_size = (img_height, img_width)\n",
    "    - batch_size = batch_size\n",
    "    - class_mode = \"categorical\"\n",
    "\n",
    "\n",
    "----------------------------------------------------------\n",
    "2. Test Loader Setting\n",
    "\n",
    "    - directory = validation_data_dir,\n",
    "    - target_size = (img_height, img_width)\n",
    "    - class_mode = \"categorical\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 977,
     "status": "ok",
     "timestamp": 1533213323983,
     "user": {
      "displayName": "Mohammad Doosti Lakhani",
      "photoUrl": "//lh5.googleusercontent.com/-UVQKn-_bjas/AAAAAAAAAAI/AAAAAAAAACc/Nr22-zVsFzc/s50-c-k-no/photo.jpg",
      "userId": "112537701770884493684"
     },
     "user_tz": -270
    },
    "id": "jOl9gRGrY99U",
    "outputId": "aaf8d898-c2fa-4d99-b033-17422a096726"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 244 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        directory = train_data_dir,\n",
    "        target_size = (img_height, img_width),\n",
    "        batch_size = batch_size,\n",
    "        class_mode = \"categorical\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 844,
     "status": "ok",
     "timestamp": 1533213518181,
     "user": {
      "displayName": "Mohammad Doosti Lakhani",
      "photoUrl": "//lh5.googleusercontent.com/-UVQKn-_bjas/AAAAAAAAAAI/AAAAAAAAACc/Nr22-zVsFzc/s50-c-k-no/photo.jpg",
      "userId": "112537701770884493684"
     },
     "user_tz": -270
    },
    "id": "vy1NGosho9OC",
    "outputId": "4128cce6-9019-44ea-bab3-50dbba2e56c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 153 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "        directory = validation_data_dir,\n",
    "        target_size = (img_height, img_width),\n",
    "        batch_size = batch_size,\n",
    "        class_mode = \"categorical\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ZehVFyflY99a"
   },
   "outputs": [],
   "source": [
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2859
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1202862,
     "status": "ok",
     "timestamp": 1533214753179,
     "user": {
      "displayName": "Mohammad Doosti Lakhani",
      "photoUrl": "//lh5.googleusercontent.com/-UVQKn-_bjas/AAAAAAAAAAI/AAAAAAAAACc/Nr22-zVsFzc/s50-c-k-no/photo.jpg",
      "userId": "112537701770884493684"
     },
     "user_tz": -270
    },
    "id": "l0_1uLD2Y99d",
    "outputId": "a6b1c3a9-da11-4e0d-af18-c45139dd1cc2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=50, validation_data=<keras.pre..., callbacks=[<keras.ca..., steps_per_epoch=15, validation_steps=153)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15/15 [==============================] - 35s 2s/step - loss: 1.2485 - acc: 0.5217 - val_loss: 0.8491 - val_acc: 0.5830\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.58301, saving model to vgg16_1.h5\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 1.2166 - acc: 0.4908 - val_loss: 0.6597 - val_acc: 0.6714\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.58301 to 0.67136, saving model to vgg16_1.h5\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.9619 - acc: 0.5987 - val_loss: 0.5806 - val_acc: 0.7157\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.67136 to 0.71575, saving model to vgg16_1.h5\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.8450 - acc: 0.6583 - val_loss: 0.5650 - val_acc: 0.7315\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.71575 to 0.73154, saving model to vgg16_1.h5\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.8990 - acc: 0.5890 - val_loss: 0.6283 - val_acc: 0.7239\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.73154\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.7612 - acc: 0.6748 - val_loss: 0.5668 - val_acc: 0.7332\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.73154 to 0.73325, saving model to vgg16_1.h5\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.6040 - acc: 0.7241 - val_loss: 0.5420 - val_acc: 0.7653\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.73325 to 0.76526, saving model to vgg16_1.h5\n",
      "Epoch 8/50\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.7423 - acc: 0.682315/15 [==============================] - 30s 2s/step - loss: 0.7908 - acc: 0.6750 - val_loss: 0.4919 - val_acc: 0.7704\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.76526 to 0.77038, saving model to vgg16_1.h5\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.7772 - acc: 0.6748 - val_loss: 0.4763 - val_acc: 0.7802\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.77038 to 0.78020, saving model to vgg16_1.h5\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.6288 - acc: 0.7575 - val_loss: 0.4973 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.78020\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.7777 - acc: 0.6833 - val_loss: 0.4836 - val_acc: 0.7682\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.78020\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.6729 - acc: 0.7148 - val_loss: 0.5412 - val_acc: 0.7593\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.78020\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.5919 - acc: 0.7292 - val_loss: 0.4781 - val_acc: 0.7721\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.78020\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.6027 - acc: 0.7416 - val_loss: 0.4551 - val_acc: 0.7892\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.78020 to 0.78916, saving model to vgg16_1.h5\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.5688 - acc: 0.7416 - val_loss: 0.4573 - val_acc: 0.8062\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.78916 to 0.80623, saving model to vgg16_1.h5\n",
      "Epoch 16/50\n",
      " 2/15 [===>..........................] - ETA: 1s - loss: 0.8281 - acc: 0.593815/15 [==============================] - 29s 2s/step - loss: 0.5954 - acc: 0.7082 - val_loss: 0.4442 - val_acc: 0.8079\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.80623 to 0.80794, saving model to vgg16_1.h5\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 28s 2s/step - loss: 0.5033 - acc: 0.7708 - val_loss: 0.4264 - val_acc: 0.8118\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.80794 to 0.81178, saving model to vgg16_1.h5\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.5799 - acc: 0.7416 - val_loss: 0.4390 - val_acc: 0.8028\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.81178\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.6328 - acc: 0.7349 - val_loss: 0.4132 - val_acc: 0.8160\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.81178 to 0.81605, saving model to vgg16_1.h5\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.6344 - acc: 0.7375 - val_loss: 0.4148 - val_acc: 0.8054\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.81605\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 30s 2s/step - loss: 0.4885 - acc: 0.8167 - val_loss: 0.4223 - val_acc: 0.8105\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.81605\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 30s 2s/step - loss: 0.5178 - acc: 0.7776 - val_loss: 0.4301 - val_acc: 0.8028\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.81605\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.4706 - acc: 0.8292 - val_loss: 0.4331 - val_acc: 0.8050\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.81605\n",
      "Epoch 24/50\n",
      " 1/15 [=>............................] - ETA: 1s - loss: 0.7123 - acc: 0.750015/15 [==============================] - 29s 2s/step - loss: 0.6524 - acc: 0.7341 - val_loss: 0.4510 - val_acc: 0.8037\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.81605\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.5212 - acc: 0.7910 - val_loss: 0.4071 - val_acc: 0.8190\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.81605 to 0.81904, saving model to vgg16_1.h5\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.4066 - acc: 0.8411 - val_loss: 0.4720 - val_acc: 0.7960\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.81904\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.5890 - acc: 0.7383 - val_loss: 0.4047 - val_acc: 0.8263\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.81904 to 0.82629, saving model to vgg16_1.h5\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.3774 - acc: 0.8161 - val_loss: 0.4152 - val_acc: 0.8289\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.82629 to 0.82885, saving model to vgg16_1.h5\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.4538 - acc: 0.7801 - val_loss: 0.4305 - val_acc: 0.8186\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.82885\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.4034 - acc: 0.8414 - val_loss: 0.3868 - val_acc: 0.8382\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.82885 to 0.83824, saving model to vgg16_1.h5\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.4488 - acc: 0.8083 - val_loss: 0.4093 - val_acc: 0.8224\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.83824\n",
      "Epoch 32/50\n",
      " 2/15 [===>..........................] - ETA: 1s - loss: 0.3583 - acc: 0.875015/15 [==============================] - 29s 2s/step - loss: 0.4552 - acc: 0.7918 - val_loss: 0.4152 - val_acc: 0.8186\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.83824\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 28s 2s/step - loss: 0.4105 - acc: 0.8252 - val_loss: 0.3961 - val_acc: 0.8254\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.83824\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.4323 - acc: 0.7952 - val_loss: 0.3979 - val_acc: 0.8284\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.83824\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.3381 - acc: 0.8750 - val_loss: 0.4063 - val_acc: 0.8182\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.83824\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.3699 - acc: 0.8085 - val_loss: 0.4527 - val_acc: 0.8028\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.83824\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.3304 - acc: 0.8364 - val_loss: 0.3873 - val_acc: 0.8318\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.83824\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.4274 - acc: 0.8202 - val_loss: 0.3761 - val_acc: 0.8353\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.83824\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.4019 - acc: 0.8375 - val_loss: 0.4087 - val_acc: 0.8254\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.83824\n",
      "Epoch 40/50\n",
      " 8/15 [===============>..............] - ETA: 0s - loss: 0.4597 - acc: 0.789115/15 [==============================] - 29s 2s/step - loss: 0.3524 - acc: 0.8470 - val_loss: 0.3752 - val_acc: 0.8314\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.83824\n",
      "Epoch 00040: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd996854940>"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model \n",
    "model_final.fit_generator(train_generator,\n",
    "        samples_per_epoch = nb_train_samples,\n",
    "        epochs = epochs,\n",
    "        validation_data = valid_generator,\n",
    "        nb_val_samples = nb_validation_samples,\n",
    "        callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-iSLGkKtY99g"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "default_view": {},
   "name": "3. CNN Hands-on.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
